{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from feature_engine import categorical_encoders as ce\n",
    "import feature_engine.missing_data_imputers as mdi\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to clarify some questions regarding specific aspects of some **Feature Engineering** steps, towards improving model's performance.\n",
    "\n",
    "The questions raised and clarified are:\n",
    "- Question 1: Comparison of the performance of **One Hot Encoding** vs **Top One Hot Encoding** vs **Ordinal Encoding + Rare Label Encoding** with a high number of features\n",
    "\n",
    "- Question 2: Importance of **Monotonic relationship** between the features and target in **Linear Models (Lasso)** and **Tree Based models (Random Forest)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"house-prices-advanced-regression-techniques/train.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of the variable types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº Continuous variables: 19\n",
      "Nº of Discrete variables: 13\n",
      "Nº of Categorical variables: 43\n",
      "Nº of variables with Year information: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Special Case\n",
    "year_vars = [v for v in data.columns if 'Yr' in v or 'Year' in v]\n",
    "\n",
    "categorical_vars = [v for v in data.columns if data[v].dtype == 'O']\n",
    "\n",
    "discrete_vars = [\n",
    "    v for v in data.columns if v not in categorical_vars and v not in year_vars and len(data[v].unique()) < 15\n",
    "]\n",
    "\n",
    "continuous_vars = [\n",
    "    v for v in data.columns if v not in categorical_vars and v not in year_vars and v not in discrete_vars and v not in ['Id', 'SalePrice']\n",
    "]\n",
    "\n",
    "print('Nº Continuous variables: {}'.format(len(continuous_vars)))\n",
    "print('Nº of Discrete variables: {}'.format(len(discrete_vars)))\n",
    "print('Nº of Categorical variables: {}'.format(len(categorical_vars)))\n",
    "\n",
    "print('Nº of variables with Year information: {}'.format(len(year_vars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altough they are discrete variables, the variables with **Year** information would be considered continuous due to the high cardinality. Therefore, a special category *year_vars* was created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OverallQual',\n",
       " 'OverallCond',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageCars',\n",
       " 'PoolArea',\n",
       " 'MoSold']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discrete_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing the Discrete Variables, we can see that there is a meaning and relation between the numbers in these columns. That is, the rows where the variable is 4 are closer to the rows where the variable is 3, than the variables where the variable is 1. Therefore, none of these Discrete Variables is going to be considered Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(['Id', 'SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Cardinality:\n",
      "\n",
      " [['MSZoning' '5']\n",
      " ['PavedDrive' '3']\n",
      " ['Functional' '6']\n",
      " ['KitchenQual' '4']\n",
      " ['CentralAir' '2']\n",
      " ['HeatingQC' '5']\n",
      " ['Heating' '6']\n",
      " ['SaleType' '9']\n",
      " ['Foundation' '6']\n",
      " ['ExterCond' '5']\n",
      " ['ExterQual' '4']\n",
      " ['Exterior2nd' '16']\n",
      " ['Exterior1st' '15']\n",
      " ['RoofMatl' '7']\n",
      " ['SaleCondition' '6']\n",
      " ['HouseStyle' '8']\n",
      " ['Street' '2']\n",
      " ['LotShape' '4']\n",
      " ['RoofStyle' '6']\n",
      " ['Utilities' '2']\n",
      " ['LotConfig' '5']\n",
      " ['LandContour' '4']\n",
      " ['BldgType' '5']\n",
      " ['LandSlope' '3']\n",
      " ['Neighborhood' '25']\n",
      " ['Condition1' '9']\n",
      " ['Condition2' '6']]\n"
     ]
    }
   ],
   "source": [
    "#analysis of categorical variables with no Missing Values\n",
    "#only the features with no Missing Values will be used\n",
    "\n",
    "null_percentages = X_train[categorical_vars].isnull().sum() / len(X_train)\n",
    "null_percentages.sort_values(na_position='first', ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "categories_info = np.array([[index, len(X_train[index].unique())] for index, value in null_percentages.items() if value == 0])\n",
    "print(\"Features Cardinality:\\n\\n\", categories_info)\n",
    "categorical_indexes = categories_info[:, 0]\n",
    "\n",
    "X_train_q1 = X_train[categorical_indexes]\n",
    "X_test_q1 = X_test[categorical_indexes]\n",
    "\n",
    "X_train_q2 = X_train[categorical_indexes]\n",
    "X_test_q2 = X_test[categorical_indexes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "Comparison of the performance of **One Hot Encoding** vs **Top One Hot Encoding** vs **Ordinal Encoding + Rare Label Encoding** with a high number of features\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielazevedo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 143554499048.34082, tolerance: 719132949.923008\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "#1 One Hot Encoding\n",
    "\n",
    "#One Hot Encoding\n",
    "encoder = OneHotEncoder(categories='auto', handle_unknown='ignore', sparse=False)\n",
    "encoder.fit(X_train_q1)\n",
    "\n",
    "X_train_ohe = pd.DataFrame(encoder.transform(X_train_q1))\n",
    "X_test_ohe = pd.DataFrame(encoder.transform(X_test_q1))\n",
    "\n",
    "\n",
    "lasso_model = Lasso(random_state=0)\n",
    "lasso_model.fit(X_train_ohe, y_train)\n",
    "\n",
    "\n",
    "ohe_results = lasso_model.predict(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielazevedo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7148392315.560547, tolerance: 719132949.923008\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "#2 Top One Hot Encoding\n",
    "\n",
    "n_top = 7\n",
    "\n",
    "#Top One Hot Encoding\n",
    "encoder = ce.OneHotCategoricalEncoder(top_categories = n_top)\n",
    "encoder.fit(X_train_q1)\n",
    "\n",
    "X_train_top_ohe = pd.DataFrame(encoder.transform(X_train_q1))\n",
    "X_test_top_ohe = pd.DataFrame(encoder.transform(X_test_q1))\n",
    "\n",
    "\n",
    "#Lasso model\n",
    "lasso_model = Lasso(random_state=0)\n",
    "lasso_model.fit(X_train_top_ohe, y_train)\n",
    "\n",
    "\n",
    "top_ohe_results = lasso_model.predict(X_test_top_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Ordinal Encoding + Rare Label Encoding\n",
    "\n",
    "#Rare Label Encoding\n",
    "rare_encoder = ce.RareLabelCategoricalEncoder(n_categories = 5)\n",
    "rare_encoder.fit(X_train_q1)\n",
    "\n",
    "X_train_ordinal = rare_encoder.transform(X_train_q1)\n",
    "X_test_ordinal = rare_encoder.transform(X_test_q1)\n",
    "\n",
    "#Ordinal Encoding\n",
    "encoder = ce.OrdinalCategoricalEncoder()\n",
    "encoder.fit(X_train_ordinal, y_train)\n",
    "\n",
    "X_train_ordinal = pd.DataFrame(encoder.transform(X_train_ordinal))\n",
    "X_test_ordinal = pd.DataFrame(encoder.transform(X_test_ordinal))\n",
    "\n",
    "\n",
    "#Lasso model\n",
    "lasso_model = Lasso(random_state=0)\n",
    "lasso_model.fit(X_train_ordinal, y_train)\n",
    "\n",
    "\n",
    "ordinal_results = lasso_model.predict(X_test_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Approach 1:  (1168, 178)\n",
      "Shape Approach 2:  (1168, 138)\n",
      "Shape Approach 3:  (1168, 27)\n",
      "\n",
      "MSE Approach 1:  2581889240.312276 \n",
      "MSE Approach 2:  2566542069.838165 \n",
      "MSE Approach 3:  3028271362.8342156\n"
     ]
    }
   ],
   "source": [
    "#Compare the Results of the three Approaches\n",
    "\n",
    "print(\"Shape Approach 1: \", X_train_ohe.shape)\n",
    "print(\"Shape Approach 2: \", X_train_top_ohe.shape)\n",
    "print(\"Shape Approach 3: \", X_train_ordinal.shape)\n",
    "\n",
    "mse_approach_1 = mean_squared_error(y_true = y_test, y_pred = ohe_results)\n",
    "mse_approach_2 = mean_squared_error(y_true = y_test, y_pred = top_ohe_results)\n",
    "mse_approach_3 = mean_squared_error(y_true = y_test, y_pred = ordinal_results)\n",
    "\n",
    "\n",
    "print(\"\\nMSE Approach 1: \", mse_approach_1, \"\\nMSE Approach 2: \", mse_approach_2, \"\\nMSE Approach 3: \", mse_approach_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "\n",
    "As we may have suspected, when the data dimensionality is high (significant number of features), the **One Hot Encoding** method increases significantly the feature space, which will increase the sparsity in the training data and therefore decrease the model performance.\n",
    "\n",
    "In these cases, it may be better to one hot encode only the *top n* categories of each feature and group the remaining in one single category, which is what **Top One Hot Encoding** does. This way, the feature space will not be increase so significantly, which will, in this case, lead to a slight increase in the model's performance.\n",
    "\n",
    "The last approach **Ordinal Encoding + Rare Label Encoding** was the one with the lower performance, this was expected as by performing ordinal encoding, some relationships between the encoded categories (1, 2, 3, ...) may be created, when, in the reality, they do not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Importance of **Monotonic relationship** between the features and target in **Linear Models (Lasso)** and **Tree Based models (Random Forest)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<br><br>Lasso - Linear Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE Approach 1:  4388424052.668934 \n",
      "MSE Approach 2:  3028271362.8342156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#1. Ordinal encoding is arbitrarly\n",
    "q2_pipe_arbitrary = Pipeline([\n",
    "    \n",
    "    ('rare_label_enc',\n",
    "     ce.RareLabelCategoricalEncoder(tol=0.05,\n",
    "                                    n_categories=5)),\n",
    "    ('categorical_enc',\n",
    "     ce.OrdinalCategoricalEncoder(encoding_method = 'arbitrary')),\n",
    "\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "#2. Ordinal encoding is performed aiming to create a monotonic relationship between features and variables\n",
    "q2_pipe_ordered = Pipeline([\n",
    "    \n",
    "    ('rare_label_enc',\n",
    "     ce.RareLabelCategoricalEncoder(tol=0.05,\n",
    "                                    n_categories=5)),\n",
    "    ('categorical_enc',\n",
    "     ce.OrdinalCategoricalEncoder(encoding_method = 'ordered')),\n",
    "\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "q2_pipe_arbitrary.fit(X_train_q2, y_train)\n",
    "q2_pipe_ordered.fit(X_train_q2, y_train)\n",
    "\n",
    "X_test_preds_arbitrary = q2_pipe_arbitrary.predict(X_test_q2)\n",
    "X_test_preds_ordered = q2_pipe_ordered.predict(X_test_q2)\n",
    "\n",
    "mse_approach_1 = mean_squared_error(y_true = y_test, y_pred = X_test_preds_arbitrary)\n",
    "mse_approach_2 = mean_squared_error(y_true = y_test, y_pred = X_test_preds_ordered)\n",
    "\n",
    "print(\"\\nMSE Approach 1: \", mse_approach_1, \"\\nMSE Approach 2: \", mse_approach_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can conclude, by guaranteeing a monotonic relationship between features and variables **(Approach 2)** the results improve signficantly comparing to arbitrary encoding **(Approach 1)**. This means that, when using **Linear Models (Lasso)**, we should aim to establish a monotonic relatioship between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<br><br>Random Forest - Tree-based Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielazevedo/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE Approach 1:  2726198411.3998837 \n",
      "MSE Approach 2:  3028271362.8342156\n"
     ]
    }
   ],
   "source": [
    "#For simplicity a Pipeline will be created for training the RF model\n",
    "\n",
    "#1. Ordinal encoding is arbitrarly\n",
    "q2_pipe_arbitrary = Pipeline([\n",
    "    \n",
    "    ('rare_label_enc',\n",
    "     ce.RareLabelCategoricalEncoder(tol=0.05,\n",
    "                                    n_categories=5)),\n",
    "    ('categorical_enc',\n",
    "     ce.OrdinalCategoricalEncoder(encoding_method = 'arbitrary')),\n",
    "\n",
    "    ('RF', RandomForestRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "#2. Ordinal encoding is performed aiming to create a monotonic relationship between features and variables\n",
    "q2_pipe_ordered = Pipeline([\n",
    "    \n",
    "    ('rare_label_enc',\n",
    "     ce.RareLabelCategoricalEncoder(tol=0.05,\n",
    "                                    n_categories=5)),\n",
    "    ('categorical_enc',\n",
    "     ce.OrdinalCategoricalEncoder(encoding_method = 'ordered')),\n",
    "\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])\n",
    "\n",
    "\n",
    "q2_pipe_arbitrary.fit(X_train_q2, y_train)\n",
    "q2_pipe_ordered.fit(X_train_q2, y_train)\n",
    "\n",
    "X_test_preds_arbitrary = q2_pipe_arbitrary.predict(X_test_q2)\n",
    "X_test_preds_ordered = q2_pipe_ordered.predict(X_test_q2)\n",
    "\n",
    "mse_approach_1 = mean_squared_error(y_true = y_test, y_pred = X_test_preds_arbitrary)\n",
    "mse_approach_2 = mean_squared_error(y_true = y_test, y_pred = X_test_preds_ordered)\n",
    "\n",
    "print(\"\\nMSE Approach 1: \", mse_approach_1, \"\\nMSE Approach 2: \", mse_approach_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concerning non linear models, as **Tree-based models (Random Forest)**, we can conclude that the monotonic relationship is not an requirement for creating the model. In fact, the result of the **Approach 2** (non monotonic relationships between variables) is better comparing to **Approach 1** (monotonic relationships between variables), although the difference is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "In conclusion, we confirmed that, when dealing with **Linear Models**, it is important to garantee a monotonic relationship between each independent variable and the target. When dealing with **Non Linear Model**s, as Tree-based models, the monotonic relationship in the input data is not a mandatory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
